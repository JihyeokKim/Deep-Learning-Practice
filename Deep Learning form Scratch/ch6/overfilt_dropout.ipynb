{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366fab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9508fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d598fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.316874397145729\n",
      "=== epoch:1, train acc:0.08333333333333333, test acc:0.0928 ===\n",
      "train loss:2.3217140696279754\n",
      "train loss:2.3126448392094847\n",
      "train loss:2.3206294549172917\n",
      "=== epoch:2, train acc:0.08, test acc:0.093 ===\n",
      "train loss:2.3178588425798745\n",
      "train loss:2.3065358475793856\n",
      "train loss:2.3070025829733156\n",
      "=== epoch:3, train acc:0.08, test acc:0.0936 ===\n",
      "train loss:2.297228644210883\n",
      "train loss:2.302068965332181\n",
      "train loss:2.3041286476728753\n",
      "=== epoch:4, train acc:0.08, test acc:0.0948 ===\n",
      "train loss:2.308336121617031\n",
      "train loss:2.294483568644932\n",
      "train loss:2.303653035109713\n",
      "=== epoch:5, train acc:0.08, test acc:0.0962 ===\n",
      "train loss:2.2993665101884515\n",
      "train loss:2.296179371202877\n",
      "train loss:2.3085607377357578\n",
      "=== epoch:6, train acc:0.08333333333333333, test acc:0.099 ===\n",
      "train loss:2.2949667151578836\n",
      "train loss:2.3115933453157886\n",
      "train loss:2.309762073353633\n",
      "=== epoch:7, train acc:0.08333333333333333, test acc:0.101 ===\n",
      "train loss:2.306664519163067\n",
      "train loss:2.315817188355619\n",
      "train loss:2.2918912266222273\n",
      "=== epoch:8, train acc:0.08666666666666667, test acc:0.1031 ===\n",
      "train loss:2.3001105521661103\n",
      "train loss:2.306936188102821\n",
      "train loss:2.2993523548166896\n",
      "=== epoch:9, train acc:0.09, test acc:0.1068 ===\n",
      "train loss:2.3148151029268025\n",
      "train loss:2.315768312299682\n",
      "train loss:2.2952381038620087\n",
      "=== epoch:10, train acc:0.09666666666666666, test acc:0.1095 ===\n",
      "train loss:2.303340269678136\n",
      "train loss:2.2999371398599164\n",
      "train loss:2.2942292323213764\n",
      "=== epoch:11, train acc:0.10333333333333333, test acc:0.1136 ===\n",
      "train loss:2.3003418801648783\n",
      "train loss:2.2951956813138725\n",
      "train loss:2.2863042463475374\n",
      "=== epoch:12, train acc:0.11, test acc:0.1176 ===\n",
      "train loss:2.2831238272577714\n",
      "train loss:2.309728106825964\n",
      "train loss:2.294455961051911\n",
      "=== epoch:13, train acc:0.11666666666666667, test acc:0.1209 ===\n",
      "train loss:2.29566601370055\n",
      "train loss:2.295832627763224\n",
      "train loss:2.276168358188697\n",
      "=== epoch:14, train acc:0.12, test acc:0.1276 ===\n",
      "train loss:2.2820833424741576\n",
      "train loss:2.325259222757998\n",
      "train loss:2.2955658952751925\n",
      "=== epoch:15, train acc:0.12, test acc:0.1354 ===\n",
      "train loss:2.2827079886777493\n",
      "train loss:2.295647665699579\n",
      "train loss:2.2827760968916673\n",
      "=== epoch:16, train acc:0.12666666666666668, test acc:0.1418 ===\n",
      "train loss:2.290324803559565\n",
      "train loss:2.2722997153382054\n",
      "train loss:2.27877782377269\n",
      "=== epoch:17, train acc:0.13, test acc:0.1449 ===\n",
      "train loss:2.287064013833109\n",
      "train loss:2.281135920836781\n",
      "train loss:2.288864230163359\n",
      "=== epoch:18, train acc:0.14, test acc:0.1498 ===\n",
      "train loss:2.2861114257650703\n",
      "train loss:2.267865773822892\n",
      "train loss:2.2878588725770057\n",
      "=== epoch:19, train acc:0.14333333333333334, test acc:0.1566 ===\n",
      "train loss:2.2873870453868683\n",
      "train loss:2.2754640720348926\n",
      "train loss:2.2694745936102483\n",
      "=== epoch:20, train acc:0.14666666666666667, test acc:0.1571 ===\n",
      "train loss:2.2622608774790938\n",
      "train loss:2.2725818156529436\n",
      "train loss:2.2911398837873933\n",
      "=== epoch:21, train acc:0.15666666666666668, test acc:0.16 ===\n",
      "train loss:2.2699156550887007\n",
      "train loss:2.2801796065487316\n",
      "train loss:2.287524119246928\n",
      "=== epoch:22, train acc:0.15333333333333332, test acc:0.16 ===\n",
      "train loss:2.284942136774452\n",
      "train loss:2.286663101994922\n",
      "train loss:2.2902638537018953\n",
      "=== epoch:23, train acc:0.16333333333333333, test acc:0.1682 ===\n",
      "train loss:2.282516144968135\n",
      "train loss:2.2824440491786087\n",
      "train loss:2.282529102640021\n",
      "=== epoch:24, train acc:0.15666666666666668, test acc:0.1717 ===\n",
      "train loss:2.273935485649039\n",
      "train loss:2.2821646929717287\n",
      "train loss:2.2890545983658774\n",
      "=== epoch:25, train acc:0.17, test acc:0.1757 ===\n",
      "train loss:2.263882725022697\n",
      "train loss:2.2754182449110405\n",
      "train loss:2.2761535659073333\n",
      "=== epoch:26, train acc:0.18, test acc:0.1793 ===\n",
      "train loss:2.2847311130515147\n",
      "train loss:2.2751228532913963\n",
      "train loss:2.280388648717863\n",
      "=== epoch:27, train acc:0.19333333333333333, test acc:0.1827 ===\n",
      "train loss:2.283709201242406\n",
      "train loss:2.270525900744542\n",
      "train loss:2.2584377050468096\n",
      "=== epoch:28, train acc:0.19666666666666666, test acc:0.1858 ===\n",
      "train loss:2.2701479106299187\n",
      "train loss:2.2835011231586595\n",
      "train loss:2.2817827579642898\n",
      "=== epoch:29, train acc:0.20666666666666667, test acc:0.1898 ===\n",
      "train loss:2.2710569374425584\n",
      "train loss:2.275922509640828\n",
      "train loss:2.282751028707299\n",
      "=== epoch:30, train acc:0.21333333333333335, test acc:0.1961 ===\n",
      "train loss:2.273467923549419\n",
      "train loss:2.272964994778875\n",
      "train loss:2.2700570035198417\n",
      "=== epoch:31, train acc:0.21333333333333335, test acc:0.1994 ===\n",
      "train loss:2.274370020353046\n",
      "train loss:2.2628706810204244\n",
      "train loss:2.270342781208733\n",
      "=== epoch:32, train acc:0.21666666666666667, test acc:0.2018 ===\n",
      "train loss:2.274205471778015\n",
      "train loss:2.2671841319599024\n",
      "train loss:2.27285434425629\n",
      "=== epoch:33, train acc:0.22666666666666666, test acc:0.2054 ===\n",
      "train loss:2.261760668071623\n",
      "train loss:2.2784448160407154\n",
      "train loss:2.267562944482724\n",
      "=== epoch:34, train acc:0.24, test acc:0.2131 ===\n",
      "train loss:2.2839255937083736\n",
      "train loss:2.2619263841643376\n",
      "train loss:2.258813910304553\n",
      "=== epoch:35, train acc:0.25333333333333335, test acc:0.2166 ===\n",
      "train loss:2.2663231099802013\n",
      "train loss:2.270379271060211\n",
      "train loss:2.273862319045485\n",
      "=== epoch:36, train acc:0.25666666666666665, test acc:0.2173 ===\n",
      "train loss:2.266790113223591\n",
      "train loss:2.271027728242792\n",
      "train loss:2.256431667762586\n",
      "=== epoch:37, train acc:0.25666666666666665, test acc:0.2214 ===\n",
      "train loss:2.265774804565325\n",
      "train loss:2.278614121796445\n",
      "train loss:2.2717933281489144\n",
      "=== epoch:38, train acc:0.26, test acc:0.222 ===\n",
      "train loss:2.2721292584530453\n",
      "train loss:2.2549141132373247\n",
      "train loss:2.263990574558303\n",
      "=== epoch:39, train acc:0.2633333333333333, test acc:0.223 ===\n",
      "train loss:2.255796444394983\n",
      "train loss:2.248375408935269\n",
      "train loss:2.247162127989944\n",
      "=== epoch:40, train acc:0.25333333333333335, test acc:0.2244 ===\n",
      "train loss:2.276942796123091\n",
      "train loss:2.2613903298343674\n",
      "train loss:2.265843357129084\n",
      "=== epoch:41, train acc:0.25333333333333335, test acc:0.2253 ===\n",
      "train loss:2.2610856465042692\n",
      "train loss:2.2544857886538447\n",
      "train loss:2.248334830805242\n",
      "=== epoch:42, train acc:0.26, test acc:0.2263 ===\n",
      "train loss:2.2633586564186117\n",
      "train loss:2.258478636010126\n",
      "train loss:2.2686883378283538\n",
      "=== epoch:43, train acc:0.25, test acc:0.2294 ===\n",
      "train loss:2.2428869024766724\n",
      "train loss:2.2667294930358715\n",
      "train loss:2.281643487395263\n",
      "=== epoch:44, train acc:0.26, test acc:0.2301 ===\n",
      "train loss:2.2527817891824844\n",
      "train loss:2.2618921397175975\n",
      "train loss:2.2567585154191288\n",
      "=== epoch:45, train acc:0.27, test acc:0.2323 ===\n",
      "train loss:2.2539545434180854\n",
      "train loss:2.261031483103636\n",
      "train loss:2.240539284849456\n",
      "=== epoch:46, train acc:0.26666666666666666, test acc:0.2326 ===\n",
      "train loss:2.257788885906456\n",
      "train loss:2.2640481762217264\n",
      "train loss:2.2467820924589184\n",
      "=== epoch:47, train acc:0.27, test acc:0.2336 ===\n",
      "train loss:2.2654172840854123\n",
      "train loss:2.2432100744332883\n",
      "train loss:2.241759816547667\n",
      "=== epoch:48, train acc:0.2733333333333333, test acc:0.2356 ===\n",
      "train loss:2.2491434476470613\n",
      "train loss:2.2481150414674427\n",
      "train loss:2.244061608231102\n",
      "=== epoch:49, train acc:0.27666666666666667, test acc:0.2357 ===\n",
      "train loss:2.2437945154370285\n",
      "train loss:2.2605848420372143\n",
      "train loss:2.2424612568601545\n",
      "=== epoch:50, train acc:0.28, test acc:0.2369 ===\n",
      "train loss:2.2399152004006506\n",
      "train loss:2.264622756344452\n",
      "train loss:2.2586621615961793\n",
      "=== epoch:51, train acc:0.2866666666666667, test acc:0.2405 ===\n",
      "train loss:2.2236321093384195\n",
      "train loss:2.25185601378778\n",
      "train loss:2.2553115711006\n",
      "=== epoch:52, train acc:0.2866666666666667, test acc:0.2445 ===\n",
      "train loss:2.2534497327218785\n",
      "train loss:2.252598491090767\n",
      "train loss:2.2523159896614033\n",
      "=== epoch:53, train acc:0.29, test acc:0.2462 ===\n",
      "train loss:2.253090146102503\n",
      "train loss:2.24336167792062\n",
      "train loss:2.241003412578949\n",
      "=== epoch:54, train acc:0.29, test acc:0.2445 ===\n",
      "train loss:2.2360271150516913\n",
      "train loss:2.2535105417489074\n",
      "train loss:2.262320554191604\n",
      "=== epoch:55, train acc:0.29, test acc:0.2474 ===\n",
      "train loss:2.2294534973121114\n",
      "train loss:2.2331998563804594\n",
      "train loss:2.2491139704352388\n",
      "=== epoch:56, train acc:0.29, test acc:0.2464 ===\n",
      "train loss:2.259977112798589\n",
      "train loss:2.2417137578373283\n",
      "train loss:2.2346842088007035\n",
      "=== epoch:57, train acc:0.3, test acc:0.2457 ===\n",
      "train loss:2.2586959929382013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2410728835427784\n",
      "train loss:2.2392523852240966\n",
      "=== epoch:58, train acc:0.3, test acc:0.2453 ===\n",
      "train loss:2.246686819684329\n",
      "train loss:2.242319130981723\n",
      "train loss:2.2368134279229452\n",
      "=== epoch:59, train acc:0.30666666666666664, test acc:0.2474 ===\n",
      "train loss:2.2401481536662002\n",
      "train loss:2.221112614843454\n",
      "train loss:2.248569875091216\n",
      "=== epoch:60, train acc:0.31, test acc:0.2489 ===\n",
      "train loss:2.220655766255526\n",
      "train loss:2.2331802608585365\n",
      "train loss:2.252047712270307\n",
      "=== epoch:61, train acc:0.31, test acc:0.2492 ===\n",
      "train loss:2.250345329546454\n",
      "train loss:2.235186076166923\n",
      "train loss:2.2292487465139015\n",
      "=== epoch:62, train acc:0.31, test acc:0.2501 ===\n",
      "train loss:2.217972554695168\n",
      "train loss:2.248064224927692\n",
      "train loss:2.2318672666899726\n",
      "=== epoch:63, train acc:0.30333333333333334, test acc:0.2519 ===\n",
      "train loss:2.2287284184638394\n",
      "train loss:2.2409139347263562\n",
      "train loss:2.2020631198169394\n",
      "=== epoch:64, train acc:0.30333333333333334, test acc:0.2541 ===\n",
      "train loss:2.243512432166232\n",
      "train loss:2.2386630095284095\n",
      "train loss:2.2443196249437993\n",
      "=== epoch:65, train acc:0.30333333333333334, test acc:0.2544 ===\n",
      "train loss:2.2369565877823514\n",
      "train loss:2.2243066889563723\n",
      "train loss:2.1892242343745933\n",
      "=== epoch:66, train acc:0.30666666666666664, test acc:0.2543 ===\n",
      "train loss:2.227988283208534\n",
      "train loss:2.241629155615381\n",
      "train loss:2.2332121793871123\n",
      "=== epoch:67, train acc:0.31333333333333335, test acc:0.2562 ===\n",
      "train loss:2.240479565062355\n",
      "train loss:2.23873676274183\n",
      "train loss:2.2141720068248234\n",
      "=== epoch:68, train acc:0.31666666666666665, test acc:0.2589 ===\n",
      "train loss:2.2258205511294658\n",
      "train loss:2.247972809345641\n",
      "train loss:2.2164899267346785\n",
      "=== epoch:69, train acc:0.3233333333333333, test acc:0.2627 ===\n",
      "train loss:2.211699596104782\n",
      "train loss:2.2198817285169468\n",
      "train loss:2.2516309958780107\n",
      "=== epoch:70, train acc:0.32666666666666666, test acc:0.2654 ===\n",
      "train loss:2.234105086580345\n",
      "train loss:2.214565992092556\n",
      "train loss:2.2220735518011576\n",
      "=== epoch:71, train acc:0.32666666666666666, test acc:0.2682 ===\n",
      "train loss:2.23080100058082\n",
      "train loss:2.2351248770838112\n",
      "train loss:2.2370586961619052\n",
      "=== epoch:72, train acc:0.32666666666666666, test acc:0.2682 ===\n",
      "train loss:2.190391435192844\n",
      "train loss:2.1974507798885132\n",
      "train loss:2.242317369022299\n",
      "=== epoch:73, train acc:0.3333333333333333, test acc:0.2692 ===\n",
      "train loss:2.1963545924331873\n",
      "train loss:2.212230205191258\n",
      "train loss:2.2168454758703957\n",
      "=== epoch:74, train acc:0.33, test acc:0.2698 ===\n",
      "train loss:2.224198039659044\n",
      "train loss:2.217063684658902\n",
      "train loss:2.2285549997451946\n",
      "=== epoch:75, train acc:0.3333333333333333, test acc:0.2693 ===\n",
      "train loss:2.2304286116502308\n",
      "train loss:2.224448035522184\n",
      "train loss:2.222023246668188\n",
      "=== epoch:76, train acc:0.3333333333333333, test acc:0.2722 ===\n",
      "train loss:2.224093589273382\n",
      "train loss:2.227654420980705\n",
      "train loss:2.224494906361447\n",
      "=== epoch:77, train acc:0.3333333333333333, test acc:0.2713 ===\n",
      "train loss:2.2153011508794793\n",
      "train loss:2.1905339170139366\n",
      "train loss:2.2252071552053043\n",
      "=== epoch:78, train acc:0.3333333333333333, test acc:0.2716 ===\n",
      "train loss:2.176528305452921\n",
      "train loss:2.2281480118713644\n",
      "train loss:2.2065784939235313\n",
      "=== epoch:79, train acc:0.3333333333333333, test acc:0.2733 ===\n",
      "train loss:2.2147976546180392\n",
      "train loss:2.2088931574288777\n",
      "train loss:2.2130724838687867\n",
      "=== epoch:80, train acc:0.3333333333333333, test acc:0.2743 ===\n",
      "train loss:2.216268025113864\n",
      "train loss:2.221058422040366\n",
      "train loss:2.2000438970705805\n",
      "=== epoch:81, train acc:0.34, test acc:0.2763 ===\n",
      "train loss:2.1953060214565814\n",
      "train loss:2.2182414435178033\n",
      "train loss:2.173217219506456\n",
      "=== epoch:82, train acc:0.33666666666666667, test acc:0.2751 ===\n",
      "train loss:2.1976919211726105\n",
      "train loss:2.1878546335878593\n",
      "train loss:2.2049626815498526\n",
      "=== epoch:83, train acc:0.33666666666666667, test acc:0.2747 ===\n",
      "train loss:2.1868157822856755\n",
      "train loss:2.1699395566428943\n",
      "train loss:2.1920441316026804\n",
      "=== epoch:84, train acc:0.3333333333333333, test acc:0.274 ===\n",
      "train loss:2.185234071724538\n",
      "train loss:2.227969670876394\n",
      "train loss:2.1847612734983737\n",
      "=== epoch:85, train acc:0.33666666666666667, test acc:0.2755 ===\n",
      "train loss:2.2237487009823558\n",
      "train loss:2.180596313667498\n",
      "train loss:2.216156176501964\n",
      "=== epoch:86, train acc:0.33666666666666667, test acc:0.2757 ===\n",
      "train loss:2.227568128458176\n",
      "train loss:2.188398602754927\n",
      "train loss:2.1952848887773952\n",
      "=== epoch:87, train acc:0.33666666666666667, test acc:0.2768 ===\n",
      "train loss:2.186977232238511\n",
      "train loss:2.202583397051355\n",
      "train loss:2.1744715677167745\n",
      "=== epoch:88, train acc:0.33666666666666667, test acc:0.2794 ===\n",
      "train loss:2.1795241126002587\n",
      "train loss:2.19944228457203\n",
      "train loss:2.1814050410682846\n",
      "=== epoch:89, train acc:0.3433333333333333, test acc:0.2816 ===\n",
      "train loss:2.211524351774634\n",
      "train loss:2.2027617316745274\n",
      "train loss:2.20528904441613\n",
      "=== epoch:90, train acc:0.3466666666666667, test acc:0.2827 ===\n",
      "train loss:2.156450563799358\n",
      "train loss:2.174222902782177\n",
      "train loss:2.2053079813673393\n",
      "=== epoch:91, train acc:0.3433333333333333, test acc:0.285 ===\n",
      "train loss:2.1638623149911376\n",
      "train loss:2.182302699875035\n",
      "train loss:2.1534043393293105\n",
      "=== epoch:92, train acc:0.3433333333333333, test acc:0.2849 ===\n",
      "train loss:2.1947226325664047\n",
      "train loss:2.2082709118492057\n",
      "train loss:2.2275091631523516\n",
      "=== epoch:93, train acc:0.35333333333333333, test acc:0.2873 ===\n",
      "train loss:2.1641937419335444\n",
      "train loss:2.180254536791865\n",
      "train loss:2.196430770753502\n",
      "=== epoch:94, train acc:0.35, test acc:0.2889 ===\n",
      "train loss:2.196698819169544\n",
      "train loss:2.186266689916604\n",
      "train loss:2.186925183141824\n",
      "=== epoch:95, train acc:0.35, test acc:0.2889 ===\n",
      "train loss:2.1969934881617745\n",
      "train loss:2.168207230302454\n",
      "train loss:2.196376973350753\n",
      "=== epoch:96, train acc:0.35333333333333333, test acc:0.2867 ===\n",
      "train loss:2.175470834643477\n",
      "train loss:2.1958031220602927\n",
      "train loss:2.1854578515272705\n",
      "=== epoch:97, train acc:0.3466666666666667, test acc:0.2898 ===\n",
      "train loss:2.181287823024269\n",
      "train loss:2.14319954179735\n",
      "train loss:2.216766176879188\n",
      "=== epoch:98, train acc:0.35, test acc:0.2911 ===\n",
      "train loss:2.1938799487905434\n",
      "train loss:2.1684173574955925\n",
      "train loss:2.213959835318061\n",
      "=== epoch:99, train acc:0.3566666666666667, test acc:0.2947 ===\n",
      "train loss:2.1655462300396637\n",
      "train loss:2.1807606306063687\n",
      "train loss:2.1720103682691714\n",
      "=== epoch:100, train acc:0.3466666666666667, test acc:0.293 ===\n",
      "train loss:2.180639094932374\n",
      "train loss:2.1763226378879854\n",
      "train loss:2.161836496194252\n",
      "=== epoch:101, train acc:0.36333333333333334, test acc:0.2992 ===\n",
      "train loss:2.15349742573281\n",
      "train loss:2.1719799344441144\n",
      "train loss:2.1873570681880357\n",
      "=== epoch:102, train acc:0.37333333333333335, test acc:0.3004 ===\n",
      "train loss:2.1262009118312912\n",
      "train loss:2.152236955904865\n",
      "train loss:2.1906618175846635\n",
      "=== epoch:103, train acc:0.37333333333333335, test acc:0.3008 ===\n",
      "train loss:2.1782336742105315\n",
      "train loss:2.1787890280844833\n",
      "train loss:2.1276749234492103\n",
      "=== epoch:104, train acc:0.37, test acc:0.3011 ===\n",
      "train loss:2.1598175662695036\n",
      "train loss:2.1790105046547965\n",
      "train loss:2.1381790763160735\n",
      "=== epoch:105, train acc:0.37, test acc:0.3016 ===\n",
      "train loss:2.1580206736688776\n",
      "train loss:2.156173801781258\n",
      "train loss:2.1415809336411527\n",
      "=== epoch:106, train acc:0.37, test acc:0.3031 ===\n",
      "train loss:2.1279487020029793\n",
      "train loss:2.147214931086545\n",
      "train loss:2.129735420420807\n",
      "=== epoch:107, train acc:0.36, test acc:0.2984 ===\n",
      "train loss:2.1313775614545363\n",
      "train loss:2.129859913811031\n",
      "train loss:2.165353843120064\n",
      "=== epoch:108, train acc:0.36333333333333334, test acc:0.2989 ===\n",
      "train loss:2.149642759601046\n",
      "train loss:2.1575915635687086\n",
      "train loss:2.121452908584372\n",
      "=== epoch:109, train acc:0.36333333333333334, test acc:0.2982 ===\n",
      "train loss:2.1490466487065927\n",
      "train loss:2.143759205240189\n",
      "train loss:2.1750834032206168\n",
      "=== epoch:110, train acc:0.36333333333333334, test acc:0.2978 ===\n",
      "train loss:2.1432168340392965\n",
      "train loss:2.1514894165126695\n",
      "train loss:2.1547381790710953\n",
      "=== epoch:111, train acc:0.36666666666666664, test acc:0.2996 ===\n",
      "train loss:2.1537235884559722\n",
      "train loss:2.1376244715048993\n",
      "train loss:2.1517877854242835\n",
      "=== epoch:112, train acc:0.37333333333333335, test acc:0.3018 ===\n",
      "train loss:2.1542405194081624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.121675387540429\n",
      "train loss:2.118121997151212\n",
      "=== epoch:113, train acc:0.37666666666666665, test acc:0.3019 ===\n",
      "train loss:2.145691177422514\n",
      "train loss:2.157566629439428\n",
      "train loss:2.0960959047245353\n",
      "=== epoch:114, train acc:0.37333333333333335, test acc:0.3035 ===\n",
      "train loss:2.1234544945509883\n",
      "train loss:2.096869589619704\n",
      "train loss:2.116944789766651\n",
      "=== epoch:115, train acc:0.37, test acc:0.3027 ===\n",
      "train loss:2.149090124474076\n",
      "train loss:2.1106152532991036\n",
      "train loss:2.074653295894372\n",
      "=== epoch:116, train acc:0.37, test acc:0.3011 ===\n",
      "train loss:2.0927888158992825\n",
      "train loss:2.170729456788421\n",
      "train loss:2.0901820714669266\n",
      "=== epoch:117, train acc:0.37333333333333335, test acc:0.3041 ===\n",
      "train loss:2.132172940518909\n",
      "train loss:2.081355190945577\n",
      "train loss:2.128575407510053\n",
      "=== epoch:118, train acc:0.37333333333333335, test acc:0.3039 ===\n",
      "train loss:2.083137181172968\n",
      "train loss:2.1286732812803177\n",
      "train loss:2.146969888593032\n",
      "=== epoch:119, train acc:0.36333333333333334, test acc:0.3018 ===\n",
      "train loss:2.113647066465577\n",
      "train loss:2.093921591967806\n",
      "train loss:2.1276808578069244\n",
      "=== epoch:120, train acc:0.36666666666666664, test acc:0.3025 ===\n",
      "train loss:2.117677227740871\n",
      "train loss:2.137609396866675\n",
      "train loss:2.103744705242143\n",
      "=== epoch:121, train acc:0.37, test acc:0.3037 ===\n",
      "train loss:2.1193654722607618\n",
      "train loss:2.1405940776371764\n",
      "train loss:2.086341181115819\n",
      "=== epoch:122, train acc:0.37333333333333335, test acc:0.3073 ===\n",
      "train loss:2.111584276130853\n",
      "train loss:2.0909886856184143\n",
      "train loss:2.124601205605664\n",
      "=== epoch:123, train acc:0.38, test acc:0.3099 ===\n",
      "train loss:2.060591878729621\n",
      "train loss:2.063018506832951\n",
      "train loss:2.124604160133328\n",
      "=== epoch:124, train acc:0.38, test acc:0.3107 ===\n",
      "train loss:2.055586796973069\n",
      "train loss:2.1293691825901826\n",
      "train loss:2.1159667572632714\n",
      "=== epoch:125, train acc:0.38333333333333336, test acc:0.3124 ===\n",
      "train loss:2.1033341647026447\n",
      "train loss:2.047093485857367\n",
      "train loss:2.0782768783667267\n",
      "=== epoch:126, train acc:0.38333333333333336, test acc:0.3135 ===\n",
      "train loss:2.0637402104933606\n",
      "train loss:2.0872241317847777\n",
      "train loss:2.065999961135779\n",
      "=== epoch:127, train acc:0.38666666666666666, test acc:0.3146 ===\n",
      "train loss:2.1514227132578427\n",
      "train loss:2.0794064860698893\n",
      "train loss:2.0717473757408458\n",
      "=== epoch:128, train acc:0.38333333333333336, test acc:0.316 ===\n",
      "train loss:2.077277448384827\n",
      "train loss:2.1032752524507554\n",
      "train loss:2.0383675915604447\n",
      "=== epoch:129, train acc:0.38666666666666666, test acc:0.3161 ===\n",
      "train loss:2.076014982534289\n",
      "train loss:2.085204845025269\n",
      "train loss:2.1076851636801006\n",
      "=== epoch:130, train acc:0.39666666666666667, test acc:0.3163 ===\n",
      "train loss:2.07274292842974\n",
      "train loss:2.0820683398305\n",
      "train loss:2.0340369320191485\n",
      "=== epoch:131, train acc:0.39, test acc:0.3166 ===\n",
      "train loss:2.0243530587174394\n",
      "train loss:2.0605240725902543\n",
      "train loss:2.081575254241079\n",
      "=== epoch:132, train acc:0.38666666666666666, test acc:0.3169 ===\n",
      "train loss:2.0360481778725883\n",
      "train loss:2.102170378589298\n",
      "train loss:2.082443796797622\n",
      "=== epoch:133, train acc:0.3933333333333333, test acc:0.3186 ===\n",
      "train loss:2.093576989042019\n",
      "train loss:2.0789872391688955\n",
      "train loss:2.0057927961521598\n",
      "=== epoch:134, train acc:0.39666666666666667, test acc:0.3195 ===\n",
      "train loss:2.0280532165030833\n",
      "train loss:2.0800464406466666\n",
      "train loss:2.0837360857660534\n",
      "=== epoch:135, train acc:0.39666666666666667, test acc:0.3199 ===\n",
      "train loss:2.092537296007163\n",
      "train loss:2.067475322918877\n",
      "train loss:2.0158697889681023\n",
      "=== epoch:136, train acc:0.4066666666666667, test acc:0.3191 ===\n",
      "train loss:2.0419307045561483\n",
      "train loss:2.015037171271882\n",
      "train loss:2.036402256505394\n",
      "=== epoch:137, train acc:0.4033333333333333, test acc:0.3166 ===\n",
      "train loss:2.028162203370295\n",
      "train loss:2.111112852173661\n",
      "train loss:2.0499202141106774\n",
      "=== epoch:138, train acc:0.4066666666666667, test acc:0.3193 ===\n",
      "train loss:1.9875466018018186\n",
      "train loss:2.0588772092447827\n",
      "train loss:1.9994030301419026\n",
      "=== epoch:139, train acc:0.4066666666666667, test acc:0.3182 ===\n",
      "train loss:2.06341652208871\n",
      "train loss:2.0746782396692014\n",
      "train loss:2.037999542214491\n",
      "=== epoch:140, train acc:0.4066666666666667, test acc:0.3206 ===\n",
      "train loss:2.104615522879645\n",
      "train loss:2.0643929786434625\n",
      "train loss:2.0659367249427825\n",
      "=== epoch:141, train acc:0.41333333333333333, test acc:0.3246 ===\n",
      "train loss:2.050217961261601\n",
      "train loss:2.0710286864048553\n",
      "train loss:2.0289852271652355\n",
      "=== epoch:142, train acc:0.41, test acc:0.3225 ===\n",
      "train loss:2.076402400617858\n",
      "train loss:2.023479492641469\n",
      "train loss:2.029873963268452\n",
      "=== epoch:143, train acc:0.4066666666666667, test acc:0.3222 ===\n",
      "train loss:2.04310673182463\n",
      "train loss:1.9694679319386577\n",
      "train loss:1.983695955457761\n",
      "=== epoch:144, train acc:0.4066666666666667, test acc:0.3223 ===\n",
      "train loss:2.039531686324224\n",
      "train loss:2.0081649783761604\n",
      "train loss:2.0262873519628823\n",
      "=== epoch:145, train acc:0.4, test acc:0.3219 ===\n",
      "train loss:1.982215726956696\n",
      "train loss:1.9986735809874128\n",
      "train loss:1.9260403870828977\n",
      "=== epoch:146, train acc:0.4033333333333333, test acc:0.3207 ===\n",
      "train loss:1.988293609114626\n",
      "train loss:1.9861849478905353\n",
      "train loss:1.9329935097825472\n",
      "=== epoch:147, train acc:0.41, test acc:0.322 ===\n",
      "train loss:2.041818945261671\n",
      "train loss:2.0347425465488707\n",
      "train loss:1.9870616105368788\n",
      "=== epoch:148, train acc:0.41, test acc:0.3217 ===\n",
      "train loss:2.043829818897477\n",
      "train loss:1.9621005635175712\n",
      "train loss:2.077666220128445\n",
      "=== epoch:149, train acc:0.4066666666666667, test acc:0.3217 ===\n",
      "train loss:2.038391861635737\n",
      "train loss:1.9688765277655096\n",
      "train loss:1.9899350289925821\n",
      "=== epoch:150, train acc:0.41333333333333333, test acc:0.324 ===\n",
      "train loss:1.9863377930058876\n",
      "train loss:1.9590994195254425\n",
      "train loss:2.010226986910407\n",
      "=== epoch:151, train acc:0.4166666666666667, test acc:0.3284 ===\n",
      "train loss:1.9415176472558573\n",
      "train loss:1.998556272649766\n",
      "train loss:1.9928014306034558\n",
      "=== epoch:152, train acc:0.41, test acc:0.3288 ===\n",
      "train loss:1.9991761398463561\n",
      "train loss:1.9673522685219986\n",
      "train loss:1.9782841773968771\n",
      "=== epoch:153, train acc:0.41, test acc:0.3281 ===\n",
      "train loss:2.0049873638889837\n",
      "train loss:2.0187260087507006\n",
      "train loss:2.008257402137828\n",
      "=== epoch:154, train acc:0.4066666666666667, test acc:0.3316 ===\n",
      "train loss:2.0157921000540155\n",
      "train loss:1.93513604285566\n",
      "train loss:1.9428927611443125\n",
      "=== epoch:155, train acc:0.41333333333333333, test acc:0.3317 ===\n",
      "train loss:1.949889016360813\n",
      "train loss:1.9735459968416853\n",
      "train loss:1.9827803536883073\n",
      "=== epoch:156, train acc:0.41, test acc:0.3316 ===\n",
      "train loss:1.938992665101446\n",
      "train loss:1.927667923966242\n",
      "train loss:1.9805381842024026\n",
      "=== epoch:157, train acc:0.41, test acc:0.3311 ===\n",
      "train loss:2.0004610914023773\n",
      "train loss:1.8969505165530713\n",
      "train loss:1.98529055408085\n",
      "=== epoch:158, train acc:0.4166666666666667, test acc:0.3306 ===\n",
      "train loss:1.8421399415150344\n",
      "train loss:1.8886145290890086\n",
      "train loss:1.9895336213162365\n",
      "=== epoch:159, train acc:0.42, test acc:0.3313 ===\n",
      "train loss:1.9462641067535145\n",
      "train loss:1.9728012183057462\n",
      "train loss:1.8642451362233035\n",
      "=== epoch:160, train acc:0.4166666666666667, test acc:0.3311 ===\n",
      "train loss:1.9471481829888302\n",
      "train loss:1.9044195562955557\n",
      "train loss:1.9604564409770384\n",
      "=== epoch:161, train acc:0.41333333333333333, test acc:0.3324 ===\n",
      "train loss:1.8976900800845322\n",
      "train loss:1.957926836215722\n",
      "train loss:1.939236992008492\n",
      "=== epoch:162, train acc:0.4166666666666667, test acc:0.3352 ===\n",
      "train loss:1.9964950675218085\n",
      "train loss:1.920203902977583\n",
      "train loss:1.9604698677655508\n",
      "=== epoch:163, train acc:0.4166666666666667, test acc:0.3361 ===\n",
      "train loss:1.8970463748205402\n",
      "train loss:1.8783471010659654\n",
      "train loss:1.8908286836337087\n",
      "=== epoch:164, train acc:0.42, test acc:0.3372 ===\n",
      "train loss:1.9312791227730448\n",
      "train loss:1.9237664198725912\n",
      "train loss:1.951255749721686\n",
      "=== epoch:165, train acc:0.43333333333333335, test acc:0.3405 ===\n",
      "train loss:1.8146147923453901\n",
      "train loss:1.903116140220499\n",
      "train loss:1.9797449493766828\n",
      "=== epoch:166, train acc:0.42333333333333334, test acc:0.3386 ===\n",
      "train loss:1.8998576615838316\n",
      "train loss:1.8480881584443876\n",
      "train loss:1.8501704532963545\n",
      "=== epoch:167, train acc:0.4166666666666667, test acc:0.3355 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.8490621089475467\n",
      "train loss:1.908665441607137\n",
      "train loss:1.8576161367392492\n",
      "=== epoch:168, train acc:0.4266666666666667, test acc:0.34 ===\n",
      "train loss:1.8760436250201094\n",
      "train loss:1.923676620630292\n",
      "train loss:1.9167611207720454\n",
      "=== epoch:169, train acc:0.43, test acc:0.3426 ===\n",
      "train loss:1.8883742238636776\n",
      "train loss:1.948914880516943\n",
      "train loss:1.9080466399329672\n",
      "=== epoch:170, train acc:0.43, test acc:0.3438 ===\n",
      "train loss:1.8742758342285257\n",
      "train loss:1.8988896732427611\n",
      "train loss:1.8584395922784518\n",
      "=== epoch:171, train acc:0.44, test acc:0.3507 ===\n",
      "train loss:1.7975975697424678\n",
      "train loss:1.945224195567171\n",
      "train loss:1.8683177471337433\n",
      "=== epoch:172, train acc:0.45666666666666667, test acc:0.357 ===\n",
      "train loss:1.8964721944908083\n",
      "train loss:1.8885882103500737\n",
      "train loss:1.8496220397686962\n",
      "=== epoch:173, train acc:0.4533333333333333, test acc:0.3582 ===\n",
      "train loss:1.8270795164124884\n",
      "train loss:1.8885443076985047\n",
      "train loss:1.8845039637743703\n",
      "=== epoch:174, train acc:0.47, test acc:0.3612 ===\n",
      "train loss:1.8161639631280568\n",
      "train loss:1.8070143870497817\n",
      "train loss:1.8611439142075055\n",
      "=== epoch:175, train acc:0.47, test acc:0.363 ===\n",
      "train loss:1.8527637089281694\n",
      "train loss:1.8757044639025766\n",
      "train loss:1.9137212747512258\n",
      "=== epoch:176, train acc:0.4766666666666667, test acc:0.3648 ===\n",
      "train loss:1.8487760850912536\n",
      "train loss:1.8568622843958733\n",
      "train loss:1.8681051829587443\n",
      "=== epoch:177, train acc:0.4866666666666667, test acc:0.3695 ===\n",
      "train loss:1.8288135271494508\n",
      "train loss:1.8690057896982923\n",
      "train loss:1.8901168051445947\n",
      "=== epoch:178, train acc:0.4866666666666667, test acc:0.3665 ===\n",
      "train loss:1.8807525940429366\n",
      "train loss:1.8920153523306995\n",
      "train loss:1.8720622814410217\n",
      "=== epoch:179, train acc:0.48333333333333334, test acc:0.3668 ===\n",
      "train loss:1.8890901745714443\n",
      "train loss:1.9102459177751527\n",
      "train loss:1.8545233421740825\n",
      "=== epoch:180, train acc:0.4766666666666667, test acc:0.3729 ===\n",
      "train loss:1.8862050073997474\n",
      "train loss:1.9181913104485122\n",
      "train loss:1.8935396030959868\n",
      "=== epoch:181, train acc:0.48, test acc:0.3735 ===\n",
      "train loss:1.8825640641084607\n",
      "train loss:1.8615867204286505\n",
      "train loss:1.6887011148356512\n",
      "=== epoch:182, train acc:0.48, test acc:0.3689 ===\n",
      "train loss:1.7628928524109297\n",
      "train loss:1.794123576266063\n",
      "train loss:1.8246382246260204\n",
      "=== epoch:183, train acc:0.48333333333333334, test acc:0.3706 ===\n",
      "train loss:1.6250136040174004\n",
      "train loss:1.713489762931696\n",
      "train loss:1.8293753611956973\n",
      "=== epoch:184, train acc:0.48333333333333334, test acc:0.3695 ===\n",
      "train loss:1.857495711780143\n",
      "train loss:1.8568899309274542\n",
      "train loss:1.8441526826394914\n",
      "=== epoch:185, train acc:0.4866666666666667, test acc:0.3759 ===\n",
      "train loss:1.8426934296028161\n",
      "train loss:1.733952984069107\n",
      "train loss:1.731223558630977\n",
      "=== epoch:186, train acc:0.4866666666666667, test acc:0.3758 ===\n",
      "train loss:1.7125159952425164\n",
      "train loss:1.8044819660803322\n",
      "train loss:1.8129500670059824\n",
      "=== epoch:187, train acc:0.4866666666666667, test acc:0.3754 ===\n",
      "train loss:1.6802521532417005\n",
      "train loss:1.8381693224470979\n",
      "train loss:1.8153067363563664\n",
      "=== epoch:188, train acc:0.49, test acc:0.3847 ===\n",
      "train loss:1.7456646455176912\n",
      "train loss:1.6530493839818856\n",
      "train loss:1.7345202560732706\n",
      "=== epoch:189, train acc:0.49, test acc:0.3793 ===\n",
      "train loss:1.6922178708053721\n",
      "train loss:1.8439753492744047\n",
      "train loss:1.8225030677701994\n",
      "=== epoch:190, train acc:0.49, test acc:0.3808 ===\n",
      "train loss:1.7393830961584162\n",
      "train loss:1.667204611142852\n",
      "train loss:1.7335798201715429\n",
      "=== epoch:191, train acc:0.49, test acc:0.3835 ===\n",
      "train loss:1.824177049598259\n",
      "train loss:1.7427873251904997\n",
      "train loss:1.8042847325022278\n",
      "=== epoch:192, train acc:0.4866666666666667, test acc:0.385 ===\n",
      "train loss:1.7581850717248357\n",
      "train loss:1.8140489239473983\n",
      "train loss:1.6675673540257268\n",
      "=== epoch:193, train acc:0.49666666666666665, test acc:0.388 ===\n",
      "train loss:1.676645020189426\n",
      "train loss:1.8736929164132006\n",
      "train loss:1.7274226777951602\n",
      "=== epoch:194, train acc:0.49333333333333335, test acc:0.3921 ===\n",
      "train loss:1.678721187599565\n",
      "train loss:1.8270356408483956\n",
      "train loss:1.7227330544196524\n",
      "=== epoch:195, train acc:0.5033333333333333, test acc:0.3923 ===\n",
      "train loss:1.675166172376546\n",
      "train loss:1.736426771727987\n",
      "train loss:1.583790360870321\n",
      "=== epoch:196, train acc:0.49666666666666665, test acc:0.3904 ===\n",
      "train loss:1.6759758450323465\n",
      "train loss:1.7759242356448508\n",
      "train loss:1.613362811175655\n",
      "=== epoch:197, train acc:0.5, test acc:0.393 ===\n",
      "train loss:1.7422775577807232\n",
      "train loss:1.667361810248975\n",
      "train loss:1.6839478317789047\n",
      "=== epoch:198, train acc:0.49666666666666665, test acc:0.3916 ===\n",
      "train loss:1.6204865397284665\n",
      "train loss:1.6454767822076888\n",
      "train loss:1.7790841331707465\n",
      "=== epoch:199, train acc:0.49666666666666665, test acc:0.3947 ===\n",
      "train loss:1.7537489248112592\n",
      "train loss:1.7233289365248614\n",
      "train loss:1.7255496341912908\n",
      "=== epoch:200, train acc:0.5, test acc:0.399 ===\n",
      "train loss:1.678500489360506\n",
      "train loss:1.6542151582096787\n",
      "train loss:1.6460569966269958\n",
      "=== epoch:201, train acc:0.49666666666666665, test acc:0.4014 ===\n",
      "train loss:1.6883713957078934\n",
      "train loss:1.6703969819903346\n",
      "train loss:1.6663340367236785\n",
      "=== epoch:202, train acc:0.5033333333333333, test acc:0.3995 ===\n",
      "train loss:1.7310969960498093\n",
      "train loss:1.6274736176356137\n",
      "train loss:1.5980947541636796\n",
      "=== epoch:203, train acc:0.51, test acc:0.4066 ===\n",
      "train loss:1.786699584532208\n",
      "train loss:1.6552968283386251\n",
      "train loss:1.7429558714570224\n",
      "=== epoch:204, train acc:0.5133333333333333, test acc:0.4075 ===\n",
      "train loss:1.786181589732166\n",
      "train loss:1.7259928562339428\n",
      "train loss:1.6741818061015874\n",
      "=== epoch:205, train acc:0.5166666666666667, test acc:0.4128 ===\n",
      "train loss:1.7460954533448756\n",
      "train loss:1.6468951945008938\n",
      "train loss:1.6009741161405473\n",
      "=== epoch:206, train acc:0.5166666666666667, test acc:0.4143 ===\n",
      "train loss:1.6097559297278619\n",
      "train loss:1.6160672546312476\n",
      "train loss:1.6459258278428122\n",
      "=== epoch:207, train acc:0.5233333333333333, test acc:0.4177 ===\n",
      "train loss:1.5887845802825098\n",
      "train loss:1.678958840842376\n",
      "train loss:1.6393471417468404\n",
      "=== epoch:208, train acc:0.5133333333333333, test acc:0.4135 ===\n",
      "train loss:1.5927917376944298\n",
      "train loss:1.7118628702934475\n",
      "train loss:1.593801084173779\n",
      "=== epoch:209, train acc:0.5166666666666667, test acc:0.4164 ===\n",
      "train loss:1.589243503686579\n",
      "train loss:1.7646718532647478\n",
      "train loss:1.6003966288818987\n",
      "=== epoch:210, train acc:0.5366666666666666, test acc:0.4249 ===\n",
      "train loss:1.5382575816731472\n",
      "train loss:1.6130594692256954\n",
      "train loss:1.6246529050250038\n",
      "=== epoch:211, train acc:0.54, test acc:0.4252 ===\n",
      "train loss:1.5918176442010483\n",
      "train loss:1.6344316917771584\n",
      "train loss:1.6278728130838993\n",
      "=== epoch:212, train acc:0.5433333333333333, test acc:0.4265 ===\n",
      "train loss:1.6203880740473497\n",
      "train loss:1.6976653156382273\n",
      "train loss:1.6055232260729162\n",
      "=== epoch:213, train acc:0.55, test acc:0.4334 ===\n",
      "train loss:1.628205798710667\n",
      "train loss:1.5525601976864587\n",
      "train loss:1.5652162102846692\n",
      "=== epoch:214, train acc:0.55, test acc:0.4386 ===\n",
      "train loss:1.621525885831007\n",
      "train loss:1.5898839499204245\n",
      "train loss:1.613855377484618\n",
      "=== epoch:215, train acc:0.5566666666666666, test acc:0.4405 ===\n",
      "train loss:1.513668489907132\n",
      "train loss:1.5686721256952918\n",
      "train loss:1.6372920205388362\n",
      "=== epoch:216, train acc:0.5633333333333334, test acc:0.4409 ===\n",
      "train loss:1.5795406247783583\n",
      "train loss:1.4884541945332452\n",
      "train loss:1.6344661786889418\n",
      "=== epoch:217, train acc:0.5633333333333334, test acc:0.4391 ===\n",
      "train loss:1.669904992625164\n",
      "train loss:1.5566846866750776\n",
      "train loss:1.5812732977841457\n",
      "=== epoch:218, train acc:0.57, test acc:0.4483 ===\n",
      "train loss:1.5999474632503823\n",
      "train loss:1.4102984628506008\n",
      "train loss:1.5352087261054799\n",
      "=== epoch:219, train acc:0.5633333333333334, test acc:0.4449 ===\n",
      "train loss:1.5813588263199239\n",
      "train loss:1.6469808240117951\n",
      "train loss:1.5052216687205224\n",
      "=== epoch:220, train acc:0.57, test acc:0.446 ===\n",
      "train loss:1.5728361273538984\n",
      "train loss:1.6499585507471108\n",
      "train loss:1.580159821000673\n",
      "=== epoch:221, train acc:0.5733333333333334, test acc:0.4499 ===\n",
      "train loss:1.577293796315459\n",
      "train loss:1.545870989049465\n",
      "train loss:1.6191941264830532\n",
      "=== epoch:222, train acc:0.5766666666666667, test acc:0.4508 ===\n",
      "train loss:1.444329916716884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.5818097118103038\n",
      "train loss:1.5455264574081304\n",
      "=== epoch:223, train acc:0.5866666666666667, test acc:0.4535 ===\n",
      "train loss:1.6899891040659107\n",
      "train loss:1.4965626847209814\n",
      "train loss:1.4446480848281906\n",
      "=== epoch:224, train acc:0.5733333333333334, test acc:0.4548 ===\n",
      "train loss:1.6889328417990097\n",
      "train loss:1.3981453391936012\n",
      "train loss:1.40754255636586\n",
      "=== epoch:225, train acc:0.5733333333333334, test acc:0.454 ===\n",
      "train loss:1.4199665122955336\n",
      "train loss:1.4716686194765807\n",
      "train loss:1.5076248474855245\n",
      "=== epoch:226, train acc:0.5633333333333334, test acc:0.4522 ===\n",
      "train loss:1.6366372517511143\n",
      "train loss:1.4632214820519451\n",
      "train loss:1.4480841860222242\n",
      "=== epoch:227, train acc:0.5633333333333334, test acc:0.4545 ===\n",
      "train loss:1.4685182860619495\n",
      "train loss:1.3725644442383471\n",
      "train loss:1.513807041664569\n",
      "=== epoch:228, train acc:0.58, test acc:0.4547 ===\n",
      "train loss:1.6127104516863153\n",
      "train loss:1.5206364125166272\n",
      "train loss:1.379779338852499\n",
      "=== epoch:229, train acc:0.58, test acc:0.4583 ===\n",
      "train loss:1.4014194172755037\n",
      "train loss:1.378670129383837\n",
      "train loss:1.4292610207111753\n",
      "=== epoch:230, train acc:0.5766666666666667, test acc:0.4568 ===\n",
      "train loss:1.4860412086241528\n",
      "train loss:1.4529480836874473\n",
      "train loss:1.4255459752710624\n",
      "=== epoch:231, train acc:0.6033333333333334, test acc:0.4679 ===\n",
      "train loss:1.4107617161078074\n",
      "train loss:1.4854551555696929\n",
      "train loss:1.554913631720419\n",
      "=== epoch:232, train acc:0.6066666666666667, test acc:0.4734 ===\n",
      "train loss:1.5078274261089424\n",
      "train loss:1.4453917387287425\n",
      "train loss:1.4830794463279318\n",
      "=== epoch:233, train acc:0.6033333333333334, test acc:0.4769 ===\n",
      "train loss:1.4574882337339665\n",
      "train loss:1.4703354118359104\n",
      "train loss:1.5125663774677305\n",
      "=== epoch:234, train acc:0.6033333333333334, test acc:0.4803 ===\n",
      "train loss:1.5350273233187124\n",
      "train loss:1.3752837044762316\n",
      "train loss:1.3547538233098892\n",
      "=== epoch:235, train acc:0.6033333333333334, test acc:0.4794 ===\n",
      "train loss:1.4173366222885417\n",
      "train loss:1.3728597671586198\n",
      "train loss:1.4351748685794814\n",
      "=== epoch:236, train acc:0.5966666666666667, test acc:0.4778 ===\n",
      "train loss:1.561154815877308\n",
      "train loss:1.3752420259448106\n",
      "train loss:1.3746537926898759\n",
      "=== epoch:237, train acc:0.61, test acc:0.4776 ===\n",
      "train loss:1.3177933740826293\n",
      "train loss:1.3594143775278613\n",
      "train loss:1.3758066007647511\n",
      "=== epoch:238, train acc:0.6033333333333334, test acc:0.4758 ===\n",
      "train loss:1.4812283953256995\n",
      "train loss:1.4264937268903004\n",
      "train loss:1.3620509742820592\n",
      "=== epoch:239, train acc:0.6066666666666667, test acc:0.4761 ===\n",
      "train loss:1.2386673720832584\n",
      "train loss:1.5589335433219407\n",
      "train loss:1.3579884737255856\n",
      "=== epoch:240, train acc:0.6033333333333334, test acc:0.4793 ===\n",
      "train loss:1.472990242147836\n",
      "train loss:1.381477307899205\n",
      "train loss:1.3760776181709633\n",
      "=== epoch:241, train acc:0.6133333333333333, test acc:0.4833 ===\n",
      "train loss:1.3373747885377592\n",
      "train loss:1.512214347166993\n",
      "train loss:1.3244176358475748\n",
      "=== epoch:242, train acc:0.6133333333333333, test acc:0.4836 ===\n",
      "train loss:1.2999688807885565\n",
      "train loss:1.3760306028934617\n",
      "train loss:1.3329955095438597\n",
      "=== epoch:243, train acc:0.6066666666666667, test acc:0.4825 ===\n",
      "train loss:1.470818878312838\n",
      "train loss:1.3834706683277662\n",
      "train loss:1.3040061134972276\n",
      "=== epoch:244, train acc:0.59, test acc:0.4812 ===\n",
      "train loss:1.2852954118654751\n",
      "train loss:1.480826917286063\n",
      "train loss:1.3914591229720332\n",
      "=== epoch:245, train acc:0.5966666666666667, test acc:0.4832 ===\n",
      "train loss:1.3329714146872635\n",
      "train loss:1.370688345383814\n",
      "train loss:1.3582240097144942\n",
      "=== epoch:246, train acc:0.6, test acc:0.4837 ===\n",
      "train loss:1.4143590621166746\n",
      "train loss:1.282344387511138\n",
      "train loss:1.490721633450847\n",
      "=== epoch:247, train acc:0.61, test acc:0.483 ===\n",
      "train loss:1.353911001288146\n",
      "train loss:1.4454330963974837\n",
      "train loss:1.3812648069335978\n",
      "=== epoch:248, train acc:0.61, test acc:0.4849 ===\n",
      "train loss:1.4290509042413382\n",
      "train loss:1.3591841452861726\n",
      "train loss:1.3286232482325644\n",
      "=== epoch:249, train acc:0.6166666666666667, test acc:0.4874 ===\n",
      "train loss:1.3928261202889503\n",
      "train loss:1.3265506364404123\n",
      "train loss:1.3480352996749303\n",
      "=== epoch:250, train acc:0.6166666666666667, test acc:0.4895 ===\n",
      "train loss:1.3954604493924339\n",
      "train loss:1.3774920579699954\n",
      "train loss:1.418977651445578\n",
      "=== epoch:251, train acc:0.6133333333333333, test acc:0.4918 ===\n",
      "train loss:1.3039397904957317\n",
      "train loss:1.3754402565890091\n",
      "train loss:1.3220496911758093\n",
      "=== epoch:252, train acc:0.6166666666666667, test acc:0.4926 ===\n",
      "train loss:1.4658488116864898\n",
      "train loss:1.255839134715953\n",
      "train loss:1.2722241172519084\n",
      "=== epoch:253, train acc:0.6166666666666667, test acc:0.4959 ===\n",
      "train loss:1.2968951277721268\n",
      "train loss:1.2648908806672239\n",
      "train loss:1.3575747441341832\n",
      "=== epoch:254, train acc:0.6133333333333333, test acc:0.4953 ===\n",
      "train loss:1.3041028125301548\n",
      "train loss:1.2950181731800714\n",
      "train loss:1.1727721120440662\n",
      "=== epoch:255, train acc:0.6166666666666667, test acc:0.4961 ===\n",
      "train loss:1.336732758396587\n",
      "train loss:1.400886260641868\n",
      "train loss:1.2879117714042212\n",
      "=== epoch:256, train acc:0.64, test acc:0.5011 ===\n",
      "train loss:1.379234797134779\n",
      "train loss:1.3900026654473054\n",
      "train loss:1.5371610772917002\n",
      "=== epoch:257, train acc:0.6366666666666667, test acc:0.5037 ===\n",
      "train loss:1.2944418667203919\n",
      "train loss:1.463306677052207\n",
      "train loss:1.41451882897884\n",
      "=== epoch:258, train acc:0.64, test acc:0.5053 ===\n",
      "train loss:1.4373079425522517\n",
      "train loss:1.3176859371929084\n",
      "train loss:1.2657044491967004\n",
      "=== epoch:259, train acc:0.6466666666666666, test acc:0.5089 ===\n",
      "train loss:1.254575391181927\n",
      "train loss:1.3045314914945203\n",
      "train loss:1.2326729140863453\n",
      "=== epoch:260, train acc:0.6333333333333333, test acc:0.5091 ===\n",
      "train loss:1.3567175125022755\n",
      "train loss:1.2311192892595322\n",
      "train loss:1.3679217365581544\n",
      "=== epoch:261, train acc:0.6433333333333333, test acc:0.5101 ===\n",
      "train loss:1.2177906897582502\n",
      "train loss:1.2423695678751967\n",
      "train loss:1.305384831032623\n",
      "=== epoch:262, train acc:0.6366666666666667, test acc:0.5137 ===\n",
      "train loss:1.293198984078325\n",
      "train loss:1.1880490629084983\n",
      "train loss:1.2624402479311607\n",
      "=== epoch:263, train acc:0.6333333333333333, test acc:0.5127 ===\n",
      "train loss:1.264806357110737\n",
      "train loss:1.226122053747623\n",
      "train loss:1.2336137194721335\n",
      "=== epoch:264, train acc:0.6333333333333333, test acc:0.5124 ===\n",
      "train loss:1.1890349591160123\n",
      "train loss:1.314476604462547\n",
      "train loss:1.376666258104573\n",
      "=== epoch:265, train acc:0.63, test acc:0.5152 ===\n",
      "train loss:1.2627391938808288\n",
      "train loss:1.131038448930843\n",
      "train loss:1.2717588180395456\n",
      "=== epoch:266, train acc:0.6466666666666666, test acc:0.5183 ===\n",
      "train loss:1.2643684856165534\n",
      "train loss:1.2155417145719085\n",
      "train loss:1.1791389522575266\n",
      "=== epoch:267, train acc:0.6466666666666666, test acc:0.519 ===\n",
      "train loss:1.2945348255246882\n",
      "train loss:1.1669930654328977\n",
      "train loss:1.2787851642929824\n",
      "=== epoch:268, train acc:0.6466666666666666, test acc:0.5186 ===\n",
      "train loss:1.2387278309168233\n",
      "train loss:1.1348122482576994\n",
      "train loss:1.215388576810016\n",
      "=== epoch:269, train acc:0.6466666666666666, test acc:0.5192 ===\n",
      "train loss:1.2890146311467894\n",
      "train loss:1.1704685447976368\n",
      "train loss:1.2532337363044659\n",
      "=== epoch:270, train acc:0.65, test acc:0.5241 ===\n",
      "train loss:1.3031063876389817\n",
      "train loss:1.314406887737372\n",
      "train loss:1.2037785661017681\n",
      "=== epoch:271, train acc:0.6533333333333333, test acc:0.5247 ===\n",
      "train loss:1.2893770999676195\n",
      "train loss:1.079990625601714\n",
      "train loss:1.2311139618815057\n",
      "=== epoch:272, train acc:0.6466666666666666, test acc:0.5252 ===\n",
      "train loss:1.1276443919051646\n",
      "train loss:1.237131734111228\n",
      "train loss:1.3577515785352525\n",
      "=== epoch:273, train acc:0.6433333333333333, test acc:0.5237 ===\n",
      "train loss:1.2855830712718455\n",
      "train loss:1.0771561651413186\n",
      "train loss:1.3448336830328678\n",
      "=== epoch:274, train acc:0.65, test acc:0.5225 ===\n",
      "train loss:1.27544025262564\n",
      "train loss:1.2864282159339158\n",
      "train loss:1.3887474911452218\n",
      "=== epoch:275, train acc:0.6466666666666666, test acc:0.5291 ===\n",
      "train loss:1.2131062814371285\n",
      "train loss:1.2972372579435094\n",
      "train loss:1.2471357693210472\n",
      "=== epoch:276, train acc:0.6533333333333333, test acc:0.5282 ===\n",
      "train loss:1.312527224991264\n",
      "train loss:1.0994267111697864\n",
      "train loss:1.226648594954866\n",
      "=== epoch:277, train acc:0.6566666666666666, test acc:0.5293 ===\n",
      "train loss:1.2666484399759665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.007747086354116\n",
      "train loss:1.2044161479947733\n",
      "=== epoch:278, train acc:0.6533333333333333, test acc:0.5298 ===\n",
      "train loss:1.1962274577580587\n",
      "train loss:1.1252476140593826\n",
      "train loss:1.1879630751387795\n",
      "=== epoch:279, train acc:0.66, test acc:0.531 ===\n",
      "train loss:1.1751690309923253\n",
      "train loss:1.2946297699408424\n",
      "train loss:1.2714749448138847\n",
      "=== epoch:280, train acc:0.6566666666666666, test acc:0.5317 ===\n",
      "train loss:1.2820299237433397\n",
      "train loss:1.205252736355059\n",
      "train loss:1.1683459442790118\n",
      "=== epoch:281, train acc:0.6466666666666666, test acc:0.536 ===\n",
      "train loss:1.3405300773576425\n",
      "train loss:1.1287593454625566\n",
      "train loss:1.2338505495696026\n",
      "=== epoch:282, train acc:0.65, test acc:0.5371 ===\n",
      "train loss:1.2641330285702466\n",
      "train loss:1.0901755941988538\n",
      "train loss:1.1679617154159068\n",
      "=== epoch:283, train acc:0.65, test acc:0.539 ===\n",
      "train loss:1.0543316930627082\n",
      "train loss:1.2238841565339853\n",
      "train loss:1.1345322763260421\n",
      "=== epoch:284, train acc:0.65, test acc:0.5391 ===\n",
      "train loss:1.153796298435273\n",
      "train loss:1.2073169571605888\n",
      "train loss:1.2421324947315495\n",
      "=== epoch:285, train acc:0.6466666666666666, test acc:0.5388 ===\n",
      "train loss:1.2124017571934562\n",
      "train loss:1.18375470983917\n",
      "train loss:1.1923537834205593\n",
      "=== epoch:286, train acc:0.65, test acc:0.541 ===\n",
      "train loss:1.227987408775052\n",
      "train loss:1.1927298168869065\n",
      "train loss:1.0391529571760296\n",
      "=== epoch:287, train acc:0.6533333333333333, test acc:0.5431 ===\n",
      "train loss:1.1567953978092729\n",
      "train loss:1.1111269692386345\n",
      "train loss:1.0877742249672502\n",
      "=== epoch:288, train acc:0.6533333333333333, test acc:0.5416 ===\n",
      "train loss:1.1830445106894907\n",
      "train loss:1.143903985591902\n",
      "train loss:1.141085859743778\n",
      "=== epoch:289, train acc:0.6566666666666666, test acc:0.5416 ===\n",
      "train loss:1.1499460222138502\n",
      "train loss:1.2019206693760662\n",
      "train loss:1.1001816808356595\n",
      "=== epoch:290, train acc:0.66, test acc:0.5459 ===\n",
      "train loss:0.992772445332068\n",
      "train loss:1.303217745820612\n",
      "train loss:1.0759321252350185\n",
      "=== epoch:291, train acc:0.6666666666666666, test acc:0.5488 ===\n",
      "train loss:1.1846869257445851\n",
      "train loss:1.2114588898992238\n",
      "train loss:1.0263055420591012\n",
      "=== epoch:292, train acc:0.6633333333333333, test acc:0.5505 ===\n",
      "train loss:1.0501283548776243\n",
      "train loss:1.0494460245238606\n",
      "train loss:1.2064644436048906\n",
      "=== epoch:293, train acc:0.6666666666666666, test acc:0.5515 ===\n",
      "train loss:1.0296458523797967\n",
      "train loss:1.1676402098422758\n",
      "train loss:1.0020215166735817\n",
      "=== epoch:294, train acc:0.6733333333333333, test acc:0.5496 ===\n",
      "train loss:1.1007016147663502\n",
      "train loss:1.185101147705894\n",
      "train loss:1.0869822574527312\n",
      "=== epoch:295, train acc:0.67, test acc:0.5523 ===\n",
      "train loss:1.146358819237072\n",
      "train loss:1.1986044529727236\n",
      "train loss:1.0304495423725746\n",
      "=== epoch:296, train acc:0.6766666666666666, test acc:0.5549 ===\n",
      "train loss:0.8997552797755531\n",
      "train loss:1.1641563088664606\n",
      "train loss:1.1511563671843918\n",
      "=== epoch:297, train acc:0.68, test acc:0.5564 ===\n",
      "train loss:1.0856289754286004\n",
      "train loss:1.1485684388752624\n",
      "train loss:1.234783890310693\n",
      "=== epoch:298, train acc:0.68, test acc:0.5598 ===\n",
      "train loss:1.0220285480226574\n",
      "train loss:0.8937170671036653\n",
      "train loss:1.1816659934711216\n",
      "=== epoch:299, train acc:0.6933333333333334, test acc:0.5608 ===\n",
      "train loss:1.0994808146256596\n",
      "train loss:1.1473405933132765\n",
      "train loss:1.1902172265193212\n",
      "=== epoch:300, train acc:0.69, test acc:0.5658 ===\n",
      "train loss:1.0170436357275228\n",
      "train loss:1.0373781750794555\n",
      "train loss:0.9698308990842913\n",
      "=== epoch:301, train acc:0.69, test acc:0.5664 ===\n",
      "train loss:1.233100124232947\n",
      "train loss:1.0309312326202957\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5677\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6990ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
